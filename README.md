# MADE_CV_CONTEST2
Code of contest2


# Detection

Попробовал архитектуры Unet и FPN с разными бекбонами для извлечения признаков. Пробовал с mobilenetv2, resnet18, resnet34, se-resnet50. Очень долго мучался с легкими моделями, поскольку думал такого количества весов хватит - задачка вроде бы не очень сложная. Оказалось не так. se-resnet50 дал значимый прирост сразу же. Добавил повороты с аугментации. Также увеличивал размер картинки сначала до 512х512, потом в итоге до 640х640 - становилось капельку получше. Ради этого пожертвовал точностью - перевел тензоры все во float32.
Пробовал сделать нормализацию картинки такую же, как в предобученном бекбоне. Оказалось плохой идеей. Не совсем точно разобрался почему так, но взглянул на отнормализованные картинки и весь номер зачастую был полностью черный - поэтому решил убрать и стало лучше.

# Recognition

Не стал менять GRU на что-то другое, поскольку именно OCR часть в данной задаче, как мне показалось, работает достаточно хорошо. Добавил аугментации Blur и JpegCompression, поскольку обратил внимание, что модель ошибается на картинках в плохом качестве и на размытых картинках, поэтому решил искусственно это пофиксить. Также эксперементировал с размером hidden_state.
Добавил слой avgpool в конце (как было в семинаре), чтобы можно было увеличить размер с 320х32 до 320х64.
Учил модель на датасете размера х2 - на оригинальном датасете + датасете, полученном с помощью PerspectiveTransform.

# Inference
На инфере брал предсказания детекшн модели, вырезал по границами бокса прямоугольник и делал Perspective Transform. После этого применял RecognitionModel и получал предикты.
